{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9f1a833-2cff-4d20-a1b3-5386ebad009d",
   "metadata": {},
   "source": [
    "Consider following code to answer further questions:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "course_name = [‘Data Science’, ‘Machine Learning’, ‘Big Data’, ‘Data Engineer’]\n",
    "\n",
    "duration = [2,3,6,4]\n",
    "\n",
    "df = pd.DataFrame(data = {‘course_name’ : course_name, ‘duration’ : duration})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e08895-a13e-4585-9284-65f674f595bc",
   "metadata": {},
   "source": [
    "Q1. Write a code to print the data present in the second row of the dataframe, df.\n",
    "\n",
    "Ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8159752a-ad5f-4eb7-85f7-5dcfb76d9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {'course_name' : course_name, 'duration' : duration})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28691670-3f58-431b-b75c-8ba2674691cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Machine Learning\n",
       "duration                      3\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e48499-dd09-4ef5-ac4c-4d545dd3be2a",
   "metadata": {},
   "source": [
    "Q2. What is the difference between the functions loc and iloc in pandas.DataFrame?\n",
    "\n",
    "Ans.  loc (Label-based Indexing):\n",
    "\n",
    "loc is primarily used for label-based indexing, which means you select data by specifying the row and column labels.\n",
    "It uses the row and column labels to locate and retrieve data.\n",
    "When you use loc, both the start and stop indices are inclusive, which means the range is closed on both ends.\n",
    "You can use boolean arrays to filter rows and columns based on label conditions.\n",
    "\n",
    "iloc (Integer-based Indexing):\n",
    "\n",
    "iloc is primarily used for integer-based indexing, which means you select data by specifying the row and column positions using integer indices (0-based).\n",
    "It uses integer positions to locate and retrieve data.\n",
    "When you use iloc, the start index is inclusive, but the stop index is exclusive, which is similar to Python slicing.\n",
    "You cannot use label conditions; instead, you provide integer positions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca80645-d93b-4640-8899-c96fb8d87a03",
   "metadata": {},
   "source": [
    "Q3. Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df\n",
    "then find the output for both new_df.loc[2] and new_df.iloc[2]. Did you observe any difference in both the outputs? If so then explain it.\n",
    "\n",
    "Ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d22b51-9665-4ecd-b9f2-50d50043f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {'course_name' : course_name, 'duration' : duration})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e6b9335-ab29-4065-8457-de120fab7e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.reindex([3,0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0410b7a3-3ab4-465c-a6ad-bd2e4f0689e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_name</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        course_name  duration\n",
       "3     Data Engineer         4\n",
       "0      Data Science         2\n",
       "1  Machine Learning         3\n",
       "2          Big Data         6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c15bcf15-7f16-41c3-86ab-af25402222ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Big Data\n",
       "duration              6\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5571c8c0-cc71-4f64-8799-440c061d5837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Machine Learning\n",
       "duration                      3\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec274120-050b-42dd-a3ee-e9ad7e449c53",
   "metadata": {},
   "source": [
    "Here's the difference:\n",
    "\n",
    "new_df.loc[2]: This uses label-based indexing, so it returns the row with the label/index 2. In the reindexed DataFrame, the label/index 2 corresponds to the row with the label/index 1 in the original DataFrame. So, it returns the data for \"Big Data\" and duration 6, which is the row at the label/index 1 in the original DataFrame.\n",
    "\n",
    "new_df.iloc[2]: This uses integer-based indexing, so it returns the row at the integer position 2. In the reindexed DataFrame, the row at position 2 corresponds to the row at position 0 in the original DataFrame. So, it returns the data for \"Machine Learning\" and duration 3, which is the row at position 0 in the original DataFrame.\n",
    "\n",
    "The difference arises because loc and iloc reference rows differently, one based on labels and the other based on integer positions. In the reindexed DataFrame, the labels and positions have changed, which leads to the different outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cde2f759-58a6-41c9-aefb-f04f70a3c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consider the below code to answer further questions:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbbb4469-4e26-4fbd-b6af-a3b6a47c0e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_1</th>\n",
       "      <th>column_2</th>\n",
       "      <th>column_3</th>\n",
       "      <th>column_4</th>\n",
       "      <th>column_5</th>\n",
       "      <th>column_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278982</td>\n",
       "      <td>0.180913</td>\n",
       "      <td>0.582401</td>\n",
       "      <td>0.496301</td>\n",
       "      <td>0.616217</td>\n",
       "      <td>0.688804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.202794</td>\n",
       "      <td>0.117182</td>\n",
       "      <td>0.152697</td>\n",
       "      <td>0.135908</td>\n",
       "      <td>0.213530</td>\n",
       "      <td>0.631198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.247713</td>\n",
       "      <td>0.478324</td>\n",
       "      <td>0.488038</td>\n",
       "      <td>0.331553</td>\n",
       "      <td>0.729700</td>\n",
       "      <td>0.800940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406242</td>\n",
       "      <td>0.548779</td>\n",
       "      <td>0.898656</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.424662</td>\n",
       "      <td>0.192634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.248421</td>\n",
       "      <td>0.165457</td>\n",
       "      <td>0.507322</td>\n",
       "      <td>0.086169</td>\n",
       "      <td>0.513178</td>\n",
       "      <td>0.647446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.619497</td>\n",
       "      <td>0.882601</td>\n",
       "      <td>0.589579</td>\n",
       "      <td>0.822737</td>\n",
       "      <td>0.566391</td>\n",
       "      <td>0.173137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column_1  column_2  column_3  column_4  column_5  column_6\n",
       "1  0.278982  0.180913  0.582401  0.496301  0.616217  0.688804\n",
       "2  0.202794  0.117182  0.152697  0.135908  0.213530  0.631198\n",
       "3  0.247713  0.478324  0.488038  0.331553  0.729700  0.800940\n",
       "4  0.406242  0.548779  0.898656  0.985385  0.424662  0.192634\n",
       "5  0.248421  0.165457  0.507322  0.086169  0.513178  0.647446\n",
       "6  0.619497  0.882601  0.589579  0.822737  0.566391  0.173137"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f0024d-4a97-47fe-8dd2-290fa0072fdc",
   "metadata": {},
   "source": [
    "Q4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "    \n",
    "(i) mean of each and every column present in the dataframe.\n",
    "\n",
    "(ii) standard deviation of column, ‘column_2’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac8cbb5a-301e-4da9-811f-25bfe1782a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column_1    0.333941\n",
       "column_2    0.395543\n",
       "column_3    0.536449\n",
       "column_4    0.476342\n",
       "column_5    0.510613\n",
       "column_6    0.522360\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88fe9db5-3274-4592-b0c0-4bc931584993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29801026006281217"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['column_2'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12667f7b-3d7d-4bde-b2e4-995370c20424",
   "metadata": {},
   "source": [
    "Q5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the\n",
    "mean of column, column_2.\n",
    "If you are getting errors in executing it then explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c15158a4-c977-4469-b7a3-5a3354b40145",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[2, 'column_2'] = 'ram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f07639b1-2dd1-412d-9708-58fb7e56b9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_1</th>\n",
       "      <th>column_2</th>\n",
       "      <th>column_3</th>\n",
       "      <th>column_4</th>\n",
       "      <th>column_5</th>\n",
       "      <th>column_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278982</td>\n",
       "      <td>0.180913</td>\n",
       "      <td>0.582401</td>\n",
       "      <td>0.496301</td>\n",
       "      <td>0.616217</td>\n",
       "      <td>0.688804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.202794</td>\n",
       "      <td>ram</td>\n",
       "      <td>0.152697</td>\n",
       "      <td>0.135908</td>\n",
       "      <td>0.213530</td>\n",
       "      <td>0.631198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.247713</td>\n",
       "      <td>0.478324</td>\n",
       "      <td>0.488038</td>\n",
       "      <td>0.331553</td>\n",
       "      <td>0.729700</td>\n",
       "      <td>0.800940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406242</td>\n",
       "      <td>0.548779</td>\n",
       "      <td>0.898656</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.424662</td>\n",
       "      <td>0.192634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.248421</td>\n",
       "      <td>0.165457</td>\n",
       "      <td>0.507322</td>\n",
       "      <td>0.086169</td>\n",
       "      <td>0.513178</td>\n",
       "      <td>0.647446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.619497</td>\n",
       "      <td>0.882601</td>\n",
       "      <td>0.589579</td>\n",
       "      <td>0.822737</td>\n",
       "      <td>0.566391</td>\n",
       "      <td>0.173137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column_1  column_2  column_3  column_4  column_5  column_6\n",
       "1  0.278982  0.180913  0.582401  0.496301  0.616217  0.688804\n",
       "2  0.202794       ram  0.152697  0.135908  0.213530  0.631198\n",
       "3  0.247713  0.478324  0.488038  0.331553  0.729700  0.800940\n",
       "4  0.406242  0.548779  0.898656  0.985385  0.424662  0.192634\n",
       "5  0.248421  0.165457  0.507322  0.086169  0.513178  0.647446\n",
       "6  0.619497  0.882601  0.589579  0.822737  0.566391  0.173137"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c91fd789-5d44-4cc4-a397-d7d90d031727",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumn_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11829\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11830\u001b[0m     _num_doc,\n\u001b[1;32m  11831\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11846\u001b[0m ):\n\u001b[0;32m> 11847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11395\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11399\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    703\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    705\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 706\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    709\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "df1['column_2'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d32be05-5bc5-4d55-8993-89b92419f114",
   "metadata": {},
   "source": [
    "if 'column_2' initially contains numeric data (floats), you'll encounter a data type mismatch error when trying to replace it with a string. To avoid this error, you should initially set the data type of 'column_2' as an object (which can hold mixed data types) when creating the DataFrame. By setting 'column_2' as an object data type, you can store both numeric and string values in the same column, and you won't encounter a data type error when replacing the data with a string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bff0dd-f0b5-48ed-b6ce-aba8fb374a1a",
   "metadata": {},
   "source": [
    "Q6. What do you understand about the windows function in pandas and list the types of windows\n",
    "functions?\n",
    "\n",
    "Ans. In pandas, window functions, often referred to as \"rolling\" or \"expanding\" functions, are used to perform calculations on a rolling or expanding window of data within a DataFrame. These functions are particularly useful for time-series data or any data where the order of observations matters. They allow you to calculate statistics or apply custom functions to subsets of data defined by a rolling or expanding window.\n",
    "\n",
    "\n",
    "In pandas, window functions, often referred to as \"rolling\" or \"expanding\" functions, are used to perform calculations on a rolling or expanding window of data within a DataFrame. These functions are particularly useful for time-series data or any data where the order of observations matters. They allow you to calculate statistics or apply custom functions to subsets of data defined by a rolling or expanding window.\n",
    "\n",
    "The two primary types of window functions in pandas are:\n",
    "\n",
    "Rolling Window Functions:\n",
    "\n",
    "Rolling window functions perform calculations on a fixed-size window of data that \"rolls\" or slides over the DataFrame along its index.\n",
    "These functions are useful for calculating moving averages, aggregating data over a fixed time period, or computing other rolling statistics.\n",
    "Common rolling window functions include:\n",
    "\n",
    ".rolling().mean(): Calculate the rolling mean.\n",
    "\n",
    ".rolling().sum(): Calculate the rolling sum.\n",
    "\n",
    ".rolling().min(): Calculate the rolling minimum.\n",
    "\n",
    ".rolling().max(): Calculate the rolling maximum.\n",
    "\n",
    ".rolling().std(): Calculate the rolling standard deviation.\n",
    "\n",
    ".rolling().var(): Calculate the rolling variance.\n",
    "\n",
    "Custom functions using .rolling().apply()\n",
    "\n",
    "Expanding Window Functions:\n",
    "\n",
    "Expanding window functions perform calculations on an expanding window of data that starts from the beginning of the DataFrame and grows as it moves through the data.\n",
    "These functions are useful for calculating cumulative sums, exponential moving averages, or other cumulative statistics.\n",
    "Common expanding window functions include:\n",
    "\n",
    ".expanding().sum(): Calculate the expanding sum.\n",
    "\n",
    ".expanding().mean(): Calculate the expanding mean.\n",
    "\n",
    ".expanding().min(): Calculate the expanding minimum.\n",
    "\n",
    ".expanding().max(): Calculate the expanding maximum.\n",
    "\n",
    ".expanding().std(): Calculate the expanding standard deviation.\n",
    "\n",
    ".expanding().var(): Calculate the expanding variance.\n",
    "\n",
    "Custom functions using .expanding().apply().\n",
    "\n",
    "Here's a basic example of using a rolling mean function on a DataFrame:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f3ed4f-d1ed-49c8-9deb-6536a82fc2fb",
   "metadata": {},
   "source": [
    "Q7. Write a code to print only the current month and year at the time of answering this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e896b80d-8758-4737-9af9-aee632ee62f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "current_time = datetime.datetime.now()\n",
    "current_month = current_time.strftime(\"%B %Y\")\n",
    "current_month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3407828d-2736-4e3a-a234-d1e47aa5eb6d",
   "metadata": {},
   "source": [
    "Q8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and\n",
    "calculates the difference between them in days, hours, and minutes using Pandas time delta. The\n",
    "program should prompt the user to enter the dates and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57d71fd5-0675-4038-8fa9-40dd71286268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 1st date in the format YYYY-MM-DD 2023-09-13\n",
      "Enter 2nd date in the format YYYY-MM-DD 2023-09-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 days 00:00:00\n"
     ]
    }
   ],
   "source": [
    "Date1 = input(\"Enter 1st date in the format YYYY-MM-DD\")\n",
    "Date2 = input(\"Enter 2nd date in the format YYYY-MM-DD\")\n",
    "d1 = pd.to_datetime(Date1)\n",
    "d2 = pd.to_datetime(Date2)\n",
    "result = d1-d2\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a751a1a2-02c5-4829-812a-06a2fc976446",
   "metadata": {},
   "source": [
    "Q9. Write a Python program that reads a CSV file containing categorical data and converts a specified\n",
    "column to a categorical data type. The program should prompt the user to enter the file path, column\n",
    "name, and category order, and then display the sorted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c3313e4-30e6-409f-a3b4-6bbf4a0e4cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path to the CSV file:  https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\n",
      "Enter the column name to convert to categorical:  Sex\n",
      "Enter the category order (comma-separated, e.g., 'Category1,Category2,Category3'):  Category1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted DataFrame:\n",
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name  Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris  NaN  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  NaN  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  NaN  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  NaN  35.0      1   \n",
      "4                             Allen, Mr. William Henry  NaN  35.0      0   \n",
      "..                                                 ...  ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas  NaN  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  NaN  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  NaN   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell  NaN  26.0      0   \n",
      "890                                Dooley, Mr. Patrick  NaN  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "0        0         A/5 21171   7.2500   NaN        S  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "4        0            373450   8.0500   NaN        S  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "886      0            211536  13.0000   NaN        S  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "889      0            111369  30.0000  C148        C  \n",
      "890      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = input(\"Enter the path to the CSV file: \")\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path and try again.\")\n",
    "    exit(1)\n",
    "column_name = input(\"Enter the column name to convert to categorical: \")\n",
    "\n",
    "if column_name not in df.columns:\n",
    "    print(f\"Column '{column_name}' not found in the CSV file.\")\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "category_order = input(\"Enter the category order (comma-separated, e.g., 'Category1,Category2,Category3'): \")\n",
    "\n",
    "categories = [cat.strip() for cat in category_order.split(',')]\n",
    "\n",
    "\n",
    "df[column_name] = pd.Categorical(df[column_name], categories=categories, ordered=True)\n",
    "\n",
    "df_sorted = df.sort_values(by=[column_name])\n",
    "\n",
    "print(\"Sorted DataFrame:\")\n",
    "print(df_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ee9925-e681-41b9-b7fb-a3ca3deee214",
   "metadata": {},
   "source": [
    "Q10. Write a Python program that reads a CSV file containing sales data for different products and\n",
    "visualizes the data using a stacked bar chart to show the sales of each product category over time. The\n",
    "program should prompt the user to enter the file path and display the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b156cd0-8ca7-4846-a5c1-3894991a444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = input(\"Enter the path to the CSV file containing sales data: \")\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path and try again.\")\n",
    "    exit(1)\n",
    "\n",
    "category_column = input(\"Enter the column name for product category: \")\n",
    "time_column = input(\"Enter the column name for time (e.g., date): \")\n",
    "\n",
    "if category_column not in df.columns or time_column not in df.columns:\n",
    "    print(\"One or both of the specified columns not found in the CSV file.\")\n",
    "    exit(1)\n",
    "\n",
    "sales_data = df.groupby([time_column, category_column]).sum().unstack()\n",
    "\n",
    "ax = sales_data.plot(kind=\"bar\", stacked=True, figsize=(10, 6))\n",
    "\n",
    "plt.title(\"Sales of Product Categories Over Time\")\n",
    "plt.xlabel(time_column)\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.legend(title=category_column)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571635b4-b7eb-4db7-96bd-7f25f12e8a4c",
   "metadata": {},
   "source": [
    "Q11. You are given a CSV file containing student data that includes the student ID and their test score. Write\n",
    "a Python program that reads the CSV file, calculates the mean, median, and mode of the test scores, and\n",
    "displays the results in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec37ca3a-fd71-4895-9f46-24ccad92c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "\n",
    "file_path = input(\"Enter the file path of the CSV file containing student data: \")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path and try again.\")\n",
    "    exit(1)\n",
    "\n",
    "mean_score = df['Test Score'].mean()\n",
    "median_score = df['Test Score'].median()\n",
    "mode_score = statistics.multimode(df['Test Score'])  \n",
    "\n",
    "result_table = pd.DataFrame({\n",
    "    'Statistic': ['Mean', 'Median', 'Mode'],\n",
    "    'Value': [mean_score, median_score, ', '.join(map(str, mode_score))]\n",
    "})\n",
    "\n",
    "print(result_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
